Predicting Daily S&P 500 Movements Using Applied Machine Learning
Overview
This project leverages Applied Machine Learning (AML) techniques to predict daily movements of the S&P 500 index. Using Python, the workflow includes data collection, preprocessing, feature engineering, and predictive modeling to forecast market trends.

The datasets include historical financial data from Investing.com, covering S&P 500 Futures, commodities (crude oil, gold), and Forex rates (EUR/USD, GBP/USD, USD/JPY). These are used to create a robust pipeline for predicting whether the market will move up or down.

Features
Data Sources: Historical datasets from Investing.com covering financial indices, commodities, and currency pairs.
Feature Engineering: Includes lagged features, moving averages, and correlations for improved model accuracy.
Machine Learning Models:
Logistic Regression
Decision Trees
Random Forest
Gradient Boosting (e.g., XGBoost)
Evaluation Metrics: Accuracy, F1 Score, and model interpretability using feature importance.
Project Structure
Files and Directories
Final Jupyter file.ipynb: The main notebook containing data preprocessing, feature engineering, model training, and evaluation.
/datasets: Raw and processed financial datasets.
README.md: Project documentation.
Workflow
Data Collection:

Data was downloaded from Investing.com, covering:
S&P 500 Futures (target variable)
Crude oil and gold futures
Forex pairs: EUR/USD, GBP/USD, USD/JPY, USD/CNY
US Dollar Index
Datasets were merged into a single dataframe for analysis.
Data Preprocessing:

Missing values handled using forward and backward filling.
Correlation analysis to understand relationships between features.
Histograms and time-series plots for exploratory data analysis (EDA).
Feature Engineering:

Created lagged features for predictive modeling.
Calculated moving averages and volatility metrics.
Normalized and scaled the data for machine learning readiness.
Model Training:

Models used:
Logistic Regression with hyperparameter tuning.
Decision Trees for interpretability.
Random Forest for robust ensemble learning.
Gradient Boosting using XGBoost for high performance.
Data split into training (80%) and testing (20%) sets.
Evaluation:

Models were evaluated using:
Accuracy: Measure of correct predictions.
F1 Score: Balance between precision and recall.
Confusion Matrix: Understanding classification performance.
Visualization:

Time-series plots of S&P 500 closing prices.
Correlation heatmaps for feature relationships.
Feature importance visualizations from models like Random Forest.
Results
Best Model: Gradient Boosting (XGBoost)
Accuracy: 76% F1 Score: 72% 
Key Insights:
Lagged features and moving averages significantly influence predictions.
Correlation with external factors like crude oil and Forex rates affects market movements.
How to Use
Prerequisites
Python 3.x installed
Jupyter Notebook or compatible IDE
Required libraries: pandas, numpy, scikit-learn, xgboost, matplotlib, seaborn
